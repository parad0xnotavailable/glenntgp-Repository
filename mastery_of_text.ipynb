{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5d7617-09c6-4726-9cc4-aa363f091f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This block accesses the text file and assigns it to the variable pg10 as a string.\n",
    "\n",
    "'''\n",
    "\n",
    "import urllib\n",
    "text = urllib.request.urlopen(\"https://www.gutenberg.org/cache/epub/10/pg10.txt\")\n",
    "pg10 = text.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82a6a67-67ae-4a1c-b879-e5e3c157e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has 99968 lines.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This block places each line of the string into a list and then generates the count of this list as the number of lines in the string.\n",
    "\n",
    "'''\n",
    "\n",
    "lines = pg10.splitlines()\n",
    "print(f\"The file has {len(lines)} lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45949043-c541-4d2d-93eb-a89a4356cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has 795227 words.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This block \"builds\" words and adds it to a list if any of the alphabet characters appear in the string and are separated\n",
    "when the for loop encounters non-alphabet characters such as spaces or any punctuation marks. Then, the last if block exists\n",
    "to append the last word that may exist at the end of the string file which may not be automatically added to the for loop\n",
    "because the loop doesn't encounter any non-alphabet character in the string to automatically add and clear the word that is \n",
    "assigned to current_word.\n",
    "\n",
    "'''\n",
    "\n",
    "letters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "total_words = []\n",
    "current_word = ''\n",
    "\n",
    "for i in pg10:\n",
    "    if i in letters:\n",
    "        current_word += i\n",
    "\n",
    "    else:\n",
    "        if current_word:\n",
    "            total_words.append(current_word)\n",
    "            current_word = ''\n",
    "\n",
    "if current_word:\n",
    "    total_words.append(current_word)\n",
    "\n",
    "print(f\"The file has {len(total_words)} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e288a3d-d4c6-4487-a8fc-b3b51a1b8269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"apostle\" (regardless of capitalisation) appears 47 times in the file.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This block iterates through the list created in the word count block and checks for any instance of apostle, regardless of\n",
    "capitalisation or any punctuation marks placed right next to the word.\n",
    "\n",
    "'''\n",
    "\n",
    "apostle_count = 0\n",
    "for i in total_words:\n",
    "    if i.lower() == 'apostle':\n",
    "        apostle_count += 1\n",
    "\n",
    "    else:\n",
    "        apostle_count += 0\n",
    "\n",
    "print(f\"\"\"The word \"apostle\" (regardless of capitalisation) appears {apostle_count} times in the file.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f74d60-971d-48da-b8ec-d106215394e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent word in the file is \"the\".\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This block goes throught the total_words list and creates a dictionary with the key being the unique words and the value\n",
    "being the count and adds on to the current count of that word if it exists and if it doesn't, attaches a value of 1 to that\n",
    "word.Then, it finds the max word count and looks for the appropriate words that have that count and print them \n",
    "(regardless if it's 1 word or multiple words).\n",
    "\n",
    "'''\n",
    "\n",
    "word_counts = {}\n",
    "most_common_word = ''\n",
    "\n",
    "for i in total_words:\n",
    "    lower_i = i.lower()\n",
    "\n",
    "    if lower_i in word_counts:\n",
    "        word_counts[lower_i] += 1\n",
    "\n",
    "    else:\n",
    "        word_counts[lower_i] = 1\n",
    "\n",
    "max_count = max(word_counts.values())\n",
    "most_common_word = [freq_word for freq_word in word_counts if word_counts[freq_word] == max_count]\n",
    "\n",
    "if len(most_common_word) == 1:\n",
    "    most_common_word = ''.join(most_common_word)\n",
    "\n",
    "else:\n",
    "    most_common_word = ', '.join(most_common_word)\n",
    "\n",
    "print(f'The most frequent word in the file is \"{most_common_word}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce5c8d-ccc3-481b-9f01-727c31d11159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
